reg_ss <- 0
for (i in 1:length(df$Temp)) {
y <- df[,3][i]
y_hat <- (alpha +(beta)*(df[,2][i]))
y_bar <- mean(df[,3])
tot_ss <- tot_ss  + (y - y_bar)^2
res_ss <- res_ss + (y - y_hat)^2
reg_ss <- reg_ss + (y_hat - y_bar)^2
}
tot_ss
reg_ss
R_2 <- reg_ss/tot_ss
R_2
(R_2)^2/(1-R_2^2)
((R_2)^2/(1-R_2^2))*(2/53)
var.test(lm(Gas ~ Temp, df))
var.test(lm(Gas ~ Temp, df))
var.test(df$Gas, df$Temp)
((R_2)/(1-R_2))*(2/53)
((R_2)/(1-R_2))
0.18041/((R_2)/(1-R_2))
R_2
# adijust R squared is:
n <- 56
p <- 2
adj_r2 <- ((reg_ss)/(n-p))/(tot_ss/(n-1))
adj_r2
(adj_r2/(1-adj_r2))
(adj_r2/(1-adj_r2))*(2/53)
(adj_r2/(1-adj_r2))*(53/2)
((R_2)/(1-R_2))*(53/2)
47.28/((R_2)/(1-R_2))
53.99/2
1/26.99
((R_2)/(1-R_2))*(54/2)
((R_2)/(1-R_2))
((R_2)/2)
((R_2)*2)
((R_2)*2)/(1-R_2)
R_2
1-R_2
0.46/0.53
(0.46/0.53)*2
(0.46/0.53)*2/53
#################################################
# Laboratory 4 - 24/11/2021: Linear Regression ~#
#################################################
# load the library DAAG with the dataset nihills
library(DAAG)
nihills
n <- nrow(nihills)
str(nihills)
# scatterplot: dist (x) against time (y)
plot(nihills$dist, nihills$time, pch=19, xlab="distance", ylab="time")
# scatterplot: dist (x) against time (y)
plot(nihills$dist, nihills$timef, pch=19, xlab="distance", ylab="time")
# Alternatively
with(nihills, plot(dist, time, pch=19))
help(with)
# Fit the linear model 1: time = beta_0+beta_1*dist + epsilon
lm1 <- lm(time ~ dist, data=nihills)
summary(lm1)
# plot of the residuals
par(mfrow=c(2,2))
plot(lm1)
# Plot of the fitted values
par(mfrow=c(1,1))
with(nihills, plot(dist, time, pch=19))
abline(coef(lm1), col="red", lty="solid")
# same as
curve( -0.32530 + 0.20094*x, add=T, col = 3)
# same as
curve( -0.32530 + 0.20094*x, add=T, col = 3,lty="solid")
# or
curve(predict(lm1, data.frame(dist=x)), col="blue", lty="solid", lwd=2, add=TRUE)
text(13,3,expression(time==hat(beta)[0]+hat(beta)[1]*dist), col="red")
text(13,3,expression(time==hat(beta)[0]+hat(beta)[1]*dist))
points(nihills$dist, predict(lm1), col="red", pch=19, cex=0.8)
nihills[17,]
segments(nihills[17,]$dist,nihills[17,]$time,
nihills[17,]$dist,fitted(lm1)[17], lty="dashed")
# R_sq
Tot_SS <- with(nihills, sum((time-mean(time))^2))
Res_SS <- with(nihills, sum((predict(lm1)-time)^2))
Mod_SS <- with(nihills, sum((predict(lm1)-mean(time))^2))
R_sq <- 1-Res_SS/Tot_SS
Mod_SS/Tot_SS
with(nihills, cor(time, dist))^2
with(nihills, cor(time, dist))^2
library(PerformanceAnalytics)
library(PerformanceAnalytics)
chart.Correlation(nihills[,c("dist", "climb", "time")])
help(chart.correlation)
??chart.correlation
??chart.Correlation
library(PerformanceAnalytics)
??chart.Correlation
??chart.Correlation
hist(nihills$dist)
nihills
n <- nrow(nihills)
str(nihills)
# scatterplot: dist (x) against time (y)
plot(nihills$dist, nihills$timef, pch=19, xlab="distance", ylab="time")
# Alternatively
with(nihills, plot(dist, time, pch=19))
# Apart one, all the data times are lower than 2 hours. As an initial attempt,
# let’s fit a simple linear model, plot the fitted values and manually compute
# the R2
# Fit the linear model 1: time = beta_0+beta_1*dist + epsilon
lm1 <- lm(time ~ dist, data=nihills)
#################################################
# Laboratory 4 - 24/11/2021: Linear Regression ~#
#################################################
# load the library DAAG with the dataset nihills
library(DAAG)
nihills
n <- nrow(nihills)
str(nihills)
# scatterplot: dist (x) against time (y)
plot(nihills$dist, nihills$timef, pch=19, xlab="distance", ylab="time")
# Alternatively
with(nihills, plot(dist, time, pch=19))
# Apart one, all the data times are lower than 2 hours. As an initial attempt,
# let’s fit a simple linear model, plot the fitted values and manually compute
# the R2
# Fit the linear model 1: time = beta_0+beta_1*dist + epsilon
lm1 <- lm(time ~ dist, data=nihills)
summary(lm1)
# !!!!!!
# plot of the residuals
par(mfrow=c(2,2))
plot(lm1)
# Plot of the fitted values
par(mfrow=c(1,1))
with(nihills, plot(dist, time, pch=19))
# !!!!
abline(coef(lm1), col="red", lty="solid")
# same as
curve( -0.32530 + 0.20094*x, add=T, col = 3,lty="solid")
text(13,3,expression(time==hat(beta)[0]+hat(beta)[1]*dist), col="red")
# plot yi_hat
points(nihills$dist, predict(lm1), col="red", pch=19, cex=0.8)
nihills[17,]
segments(nihills[17,]$dist,nihills[17,]$time,
nihills[17,]$dist,fitted(lm1)[17], lty="dashed")
# R_sq
Tot_SS <- with(nihills, sum((time-mean(time))^2))
Res_SS <- with(nihills, sum((predict(lm1)-time)^2))
Mod_SS <- with(nihills, sum((predict(lm1)-mean(time))^2))
R_sq <- 1-Res_SS/Tot_SS
Mod_SS/Tot_SS
with(nihills, cor(time, dist))^2
hist(nihills$dist)
hist(nihills$dist,breaks=10)
hist(nihills$dist,breaks=30)
hist(nihills$dist,breaks=20)
chart.Correlation(nihills[,c("dist", "climb", "time")])
help("chart.Correlation")
# Model 2: time = beta0 + beta1*dist + beta2*climb
lm2 <- lm(time ~ dist + climb, data = nihills)
summary(lm2)
par(mfrow=c(2,2))
plot(lm2)
#We may also produce some diagnostic plots
par(mfrow=c(2,2))
plot(lm2)
summary(lm2)$coef
#or
coef(lm2)
# R-squared
summary(lm2)$adj.r.squared
# Plot the residuals against the dist variable
par(mfrow=c(1,1))
plot(nihills$dist, lm2$residuals)
abline(h=0, lty="dashed")
# Plot the residuals against the dist variable
par(mfrow=c(1,1))
plot(nihills$dist, lm2$residuals)
abline(h=0, lty="dashed")
# Model 3: time = beta0 + beta1*dist + beta2*dist^2
lm3 <- lm(time ~ dist + I(dist^2), data=nihills)
summary(lm3)
plot(nihills$dist, lm2$residuals, xlab="Dist", ylab="Residuals")
plot(nihills$dist, lm2$residuals, xlab="Dist", ylab="Residuals", pch= 16)
plot(nihills$dist, lm2$residuals, xlab="Dist", ylab="Residuals", pch= 16, col="blue")
abline(h=0, lty="dashed")
# Model 3: time = beta0 + beta1*dist + beta2*dist^2
lm3 <- lm(time ~ dist + I(dist^2), data=nihills)
summary(lm3)
# Plot of the residuals and the fitted values
par(mfrow=c(2,2))
plot(lm3)
# this model seems to improve certain aspects
par(mfrow=c(1,1))
with(nihills, plot(dist, time, pch=19))
curve(predict(lm3, data.frame(dist=x)), col="red", lty="solid", lwd=2, add=TRUE)
text(10,3,expression(time==hat(beta)[0]+hat(beta)[1]*dist+hat(beta)[1]*dist^2), col="red")
points(nihills$dist, predict(lm3), col="red", pch=19, cex=0.8)
# Look the summary of data
summary(nihills)
# Look the summary of data
summary(nihills)
# Look the histograms of time, dist and climb
par(mfrow=c(1,3))
hist(nihills$time, probability=TRUE, breaks=15)
hist(nihills$climb, probability=TRUE, breaks=15)
hist(nihills$dist, probability=TRUE, breaks=15)
# tranformation of our data is useful to alleviate some problems
# i.e
min(nihills$time)
max(nihills$time)
mean(nihills$time)
median(nihills$time)
# Transform the variable in the log-scale
#(add the variables to the nihills data.frame)
nihills$log_time<-log(nihills$time)
nihills$log_climb<-log(nihills$climb)
nihills$log_dist<-log(nihills$dist)
# See the scatterplot matrix
chart.Correlation(nihills[,c("log_time","log_climb", "log_dist")])
# see how it behaves our second model
#  Model 2: time = beta0 + beta1*dist + beta2*climb
# after transformation
lm4 <- lm(log_time ~ log_dist + log_climb, data=nihills)
summary(lm4)
# Model 2: time = beta0 + beta1*dist + beta2*climb
lm2 <- lm(time ~ dist + climb, data = nihills)
summary(lm2)
par(mfrow=c(2,2))
plot(lm4)
summary(lm4)$adj.r.squared
#######
# Compute AIC and BIC
AIC <- rbind(extractAIC(lm1)[2],extractAIC(lm2)[2],
extractAIC(lm3)[2],extractAIC(lm4)[2])
BIC <- rbind(extractAIC(lm1, k=log(n))[2],extractAIC(lm2,k=log(n))[2],
extractAIC(lm3,k=log(n))[2],extractAIC(lm4,k=log(n))[2])
cbind(AIC, BIC)
# Evaluate the prediction accuracy for the log-model:
# coverage intervals for predicted values
coverage_log <- exp(predict(lm4, interval="confidence"))
coverage_log[1:5,]
freq_coverage_log <- mean(nihills$time >= coverage_log[,2] &
nihills$time < coverage_log[,3])
# Evaluate the prediction accuracy for the log-model:
# coverage intervals for predicted values
coverage_log <- exp(predict(lm4, interval="confidence"))
coverage_log[1:5,]
freq_coverage_log <- mean(nihills$time >= coverage_log[,2] &
nihills$time < coverage_log[,3])
summary(lm1)
anova(lm1)
# Evaluate the prediction accuracy for the log-model:
# coverage intervals for predicted values
coverage_log <- exp(predict(lm4, interval="confidence"))
coverage_log[1:5,]
freq_coverage_log <- mean(nihills$time >= coverage_log[,2] &
nihills$time < coverage_log[,3])
# Evaluate the prediction accuracy for the log-model:
# coverage intervals for predicted values
# using exp to return to original scale
coverage_log <- exp(predict(lm4, interval="confidence"))
coverage_log[1:5,]
freq_coverage_log <- mean(nihills$time >= coverage_log[,2] &
nihills$time < coverage_log[,3])
coverage_log[1:5,]
freq_coverage_log <- mean(nihills$time >= coverage_log[,2] &
nihills$time < coverage_log[,3])
summary(lm1)
anova(lm1)
# Computing the F-value by hand
m0<- lm(time ~ 1, data = nihills) #just intercept beta0
m1<- lm(time ~ dist, data = nihills) #adding beta1
F<-(sum(residuals(m0)^2)-sum(residuals(m1)^2))/(sum(residuals(m1)^2)/(n-2))
tot_ss <- 0
res_ss <- 0
reg_ss <- 0
for (i in 1:length(df$Temp)) {
y <- df[,3][i]
y_hat <- (alpha +(beta)*(df[,2][i]))
y_bar <- mean(df[,3])
tot_ss <- tot_ss  + (y - y_bar)^2
res_ss <- res_ss + (y - y_hat)^2
reg_ss <- reg_ss + (y_hat - y_bar)^2
}
tot_ss
reg_ss
R_2 <- reg_ss/tot_ss
R_2  # 0.4668368 (as in previous results)
a<-R_2/(1-R_2)
a <- a/(56-2)
a
b<-R_2/(1-R_2)
b<-b*2/53
b
a/b
b/a
#computing F test by hand
#model 0
m0_df<- lm(Gas ~ 1, data = df) #just intercept beta0
lm <- lm(Gas ~ Temp, df)
summary(lm)
F <- (sum(residuals(m0_df)^2)-sum(residuals(lm)^2))/(sum(residuals(lm)^2)/(n-2))
n
n<-56
F <- (sum(residuals(m0_df)^2)-sum(residuals(lm)^2))/(sum(residuals(lm)^2)/(n-2))
F
n <- 23
pf(F, 1,21,lower.tail=FALSE)
pf
# Compute the VARIANCE INFLACTION FACTOR: vif()
vif(lm4)
#by hand
lm_log_dist_climb<- lm(log_dist ~ log_climb, data=nihills)
1/(1-summary(lm_log_dist_climb)$r.squared)
nihills$logLC = 4 + 3*nihills$log_dist - 2*nihills$climb
nihills$logLC = 4 + 3*nihills$log_dist - 2*nihills$climb
lm5 <- lm(log_time ~ log_dist+log_climb+logLC ,data=nihills)
vif(lm5)
lm_log1<- lm(log_dist ~ log_climb + logLC, data=nihills)
1/(1-summary(lm_log1)$r.squared)
lm_log2<- lm(log_climb ~ log_dist+logLC, data=nihills)
1/(1-summary(lm_log2)$r.squared)
lm_log3<- lm(logLC ~ log_dist+log_climb, data=nihills)
1/(1-summary(lm_log3)$r.squared)
#Estimate the model (log_time=beta0 + beta1*x1 +beta2*x2 )
nihills$sum <- nihills$log_climb + nihills$log_dist
#Estimate the model (log_time=beta0 + beta1*x1 +beta2*x2 )
nihills$sum <- nihills$log_climb + nihills$log_dist
nihills$diff <- nihills$log_climb - nihills$log_dist
#Estimate the model (log_time=beta0 + beta1*x1 +beta2*x2 )
nihills$sum <- nihills$log_climb + nihills$log_dist
nihills$diff <- nihills$log_climb - nihills$log_dist
lm6 <- lm(log_time ~ sum + diff, data=nihills)
# Compute the vif
vif(lm6)
#Ridge regression
library(MASS)
# Tuning parameter = 0 implies least square estimates
lm_ridge<- lm.ridge(log_time ~ log_dist + log_climb, lambda=0, data=nihills)
coef(lm_ridge)
coef(lm4)
# select lambda by GCV in the model with logLC
grid.ridge<-lm.ridge(log_time ~ log_dist + log_climb + logLC,
lambda=seq(0.1,10,0.001), data=nihills)
lambda_selected<-grid.ridge$lambda[which(grid.ridge$GCV==min(grid.ridge$GCV))]
lm_ridge_GCV <- lm.ridge(log_time ~ log_dist + log_climb + logLC,
lambda=lambda_selected, data=nihills)
coef(lm_ridge_GCV)
coef(lm5)
# select lambda by GCV in the model with logLC (the model in which
# multicollinearity is present)
grid.ridge<-lm.ridge(log_time ~ log_dist + log_climb + logLC,
lambda=seq(0.1,10,0.001), data=nihills)
lambda_selected<-grid.ridge$lambda[which(grid.ridge$GCV==min(grid.ridge$GCV))]
lm_ridge_GCV <- lm.ridge(log_time ~ log_dist + log_climb + logLC,
lambda=lambda_selected, data=nihills)
coef(lm_ridge_GCV)
coef(lm5)
# LASSO
library(lasso2)
# LASSO
# LASSO is another regularization technique involving the penalization
# with a sligthly different penalization formula
library(lasso2)
lm.lasso <- l1ce(log_time ~ log_dist + log_climb + logLC, data=nihills)
summary(lm.lasso)$coef
coef(lm.lasso)
mu_hat <- beta_0 +(beta_1)*df[,2] + beta_2*(as.numeric(df$Insul)-1)
y_res <- df$Gas - mu_hat
plot(mu_hat, y_res, pch=16, col=4)
# Read results obtained by ring.c
setwd("E://Documents/DSSC/section1")
# Read results obtained by ring.c
setwd("E:\Documents\DSSC\hpc_assignment1\section1")
# Read results obtained by ring.c
setwd("E:\Documents\DSSC\hpc_assignment1\section1")
core_ucx <- data.frame(read.csv("core_ucx.csv"))
setwd("~/DSSC/hpc_assignment1/section1")
# Read results obtained by ring.c
setwd("~/DSSC/hpc_assignment1/section1")
times <- data.frame(read.csv("results.csv"))
head(times)
View(times)
# Read results obtained by ring.c
setwd("~/DSSC/hpc_assignment1/section1")
times <- data.frame(read.csv("results.csv"))
times
times <- data.frame(read.csv("results.csv",sep='\t'))
times
times <- data.frame(read.csv("results.csv",sep=c('\t',' '))
)
times
times <- data.frame(read.csv("results.csv",sep=c('\t'))
)attach(times)
times <- data.frame(read.csv("results.csv",sep='\t'))
times
times <- data.frame(read.csv("results.csv",sep=c('\t',''))
)attach(times)
times <- data.frame(read.csv("results.csv",sep=c('\t','')))
times
times <- data.frame(read.csv("results.csv",sep=c('\t\t','')))
times <- data.frame(read.csv("results.csv",sep='\t\t'))
import codecs
times <- data.frame(read.csv("results.csv",sep='\t'))
times
read.csv('results.csv')
read("39\t0.000092\t\t0.000125", sep='\t')
print("39\t0.000092\t\t0.000125", sep='\t')
times <- data.frame(read.csv("results.csv",sep=c('\t', '\t\t'))
)
times
times <- data.frame(read.csv("results.csv",sep='\t\t')
)
times <- data.frame(read.table("results.csv",sep='\t\t')
)attach(times)
times <- data.frame(read.table("results.csv",sep='\t\t'))
times <- data.frame(read.table("results.csv",sep='\t'))
times
times <- data.frame(read.table("results.csv",sep='\t', collapse='\t'))
times
times <- data.frame(read.csv("results.csv",sep='\t', collapse='\t'))
result.csv
read.table("results.csv")
times <- data.frame(read.csv("results.csv")
)
times
times <- (read.csv("results.csv")
)
times
times <- read.table("results.csv")
times
times <- data.frame(read.table("results.csv"))
times
attach(times)
plot(n_procs, time_nonblocking, type='l')
attach(times)
plot(n_procs, time_nonblocking, type='l')
plot(times$n_procs, times$time_nonblocking, type='l')
times
times$n_procs
View(times)
times$V1
times[,-1]
times <- data.frame(read.table("results.csv"))
times[-1,]
attach(times)
colnames(times) <- c("n_procs", "time_nonblocking", "time_blocking")
times
times[-1,]
attach(times)
plot(times$n_procs, times$time_nonblocking, type='l')
layout(1)
times$n_procs
times[-1,]
colnames(times) <- c("n_procs", "time_nonblocking", "time_blocking")
times
times <- times[-1,]
times
times <- data.frame(read.table("results.csv"))
times <- times[-1,]
colnames(times) <- c("n_procs", "time_nonblocking", "time_blocking")
head(times)
times$n_procs
plot(times$n_procs, times$time_nonblocking, type='l')
times <- data.frame(read.table("results.csv"))
times <- times[-3,]
colnames(times) <- c("n_procs", "time_nonblocking", "time_blocking")
attach(times)
plot(times$n_procs, times$time_nonblocking, type='l')
times <- data.frame(read.table("results.csv"))
times <- times[-3,]
colnames(times) <- c("n_procs", "time_nonblocking", "time_blocking")
attach(times)
plot(times$n_procs, times$time_nonblocking, type='l')
head(times)
times <- data.frame(read.table("results.csv"))
times <- times[-3,]
times
times <- data.frame(read.table("results.csv"))
times <- times[-c(1:3)]
times
head(times)
View(times)
times <- data.frame(read.table("results.csv"))
times <- times[-c(1,2,3)]
head(times)
times <- data.frame(read.table("results.csv"))
times <- times[-c(1,2,3),]
head(times)
colnames(times) <- c("n_procs", "time_nonblocking", "time_blocking")
attach(times)
plot(times$n_procs, times$time_nonblocking, type='l')
plot(times$n_procs, times$time_nonblocking, type='l', xlab="N procs", ylab="Time")
ggplot(data = times, aes(x = as.factor(X.bytes), y = t.usec., color = 2,group = 1)) + geom_line() + geom_point()
ggplot(data = times, aes(x = as.factor(times$n_procs), y = time_nonblocking, color = 2,group = 1)) + geom_line() + geom_point()
ggplot(data = times, aes(x = as.factor(times$n_procs), y = times$time_nonblocking, color = 2,group = 1)) + geom_line() + geom_point()
library("ggplot2")
ggplot(data = times, aes(x = as.factor(times$n_procs), y = times$time_nonblocking, color = 2,group = 1)) + geom_line() + geom_point()
ggplot(data = times, aes(x = as.factor(times$n_procs), y = times$time_nonblocking, color = 2,group = 1)) #+ geom_line() + geom_point()
ggplot(data = times, x=times$n_procs,y = times$time_nonblocking)
ggplot(data = times, aes(x = as.factor(times$n_procs), y = times$time_nonblocking, color = 2,group = 1)) #+ geom_line() + geom_point()
ggplot(data = times, aes(x = as.factor(times$n_procs), y = times$time_nonblocking, color = 2,group = 1)) + geom_line() + geom_point()
ggplot(data = times, aes(x = times$n_procs, y = times$time_nonblocking, color = 2,group = 1)) + geom_line() + geom_point()
plot(times$n_procs, times$time_nonblocking, type='l', xlab="N procs", ylab="Time")
plot(times$n_procs, times$time_nonblocking, type='l', xlab="N procs", ylab="Time", col="blue")
plot(times$n_procs, times$time_nonblocking, type='l', xlab="N procs", ylab="Time", col=3)
plot(times$n_procs, times$time_nonblocking, type='l', xlab="N procs", ylab="Time", col=5, lwd=2)
help("points")
points(times$n_procs, times$time_nonblocking,pch=16)
points(times$n_procs, times$time_nonblocking,pch=16,col=5)
